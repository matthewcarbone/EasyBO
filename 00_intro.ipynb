{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa0b25-1b8d-467a-9b04-b81d2bccce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb1291-a057-4eea-8b48-b71f700e9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed0069-52c7-4905-b292-f2eff0dfbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_utils import MPLAdjutant\n",
    "adj = MPLAdjutant()\n",
    "adj.set_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbdb8b-64e7-4785-b861-22f6c2ceab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea8ed8-d604-44de-91ff-933490e4c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyBO import gp, bo\n",
    "from easyBO.logger import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f9c45-2f5c-4a5b-9862-b93cc9dda616",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Very simple example from the BoTorch docs using `easyBO`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd44129-3443-4836-8daf-c6116876db70",
   "metadata": {},
   "source": [
    "See [here](https://botorch.org/v/0.1.0/tutorials/fit_model_with_torch_optimizer). In this simple example, we do the following:\n",
    "1. Initialize a single task GP regressor from dummy training data\n",
    "2. Assume homoscedastic noise\n",
    "3. Train the GP hyperparameters\n",
    "4. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11655534-04c4-4137-88c9-4f1b6473038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# use regular spaced points on the interval [0, 1]\n",
    "train_x = torch.linspace(0, 1, 15)\n",
    "\n",
    "# training data needs to be explicitly multi-dimensional\n",
    "train_x = train_x.unsqueeze(1)\n",
    "\n",
    "# sample observed values and add some synthetic noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + 0.15 * torch.randn_like(train_x)\n",
    "\n",
    "# Testing grid\n",
    "grid = torch.linspace(0, 1, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd64a7-9dce-4bdb-acd5-708b47c8abcc",
   "metadata": {},
   "source": [
    "Get the initial model conditioned on the training data, and run inference on the un-optimized GP, just to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691f38e-3725-42b2-878e-d08db8447d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp.get_gp(train_x=train_x, train_y=train_y, gp_type=\"regression\")\n",
    "pre_fitting_infer = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f103de-acc5-468e-9e13-d6ed5764d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9613883-0dfa-4497-ab90-54cb680673cd",
   "metadata": {},
   "source": [
    "Now, optimize the hyper-parameters (by default, this is just a kernel of the form `Const x RBF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4820c6-8c36-4bdf-9b89-026c12b417d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = gp.train_gp_(model=model, training_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75f39c-8d66-4215-a134-550e71eacd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e408527-1152-440b-a760-7d8c7a67eda9",
   "metadata": {},
   "source": [
    "Run inference again on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be882bed-e0e1-47ed-a774-134d121821b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_fitting_infer = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70b455-303a-4255-822f-c4bf48c5850c",
   "metadata": {},
   "source": [
    "Plot them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66a271-32fc-429d-b5ce-442fb2ebfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2), sharey=True, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, pre_fitting_infer[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pre_fitting_infer['mean-2sigma'], pre_fitting_infer['mean+2sigma'], alpha=0.2, color=\"red\", linewidth=0)\n",
    "\n",
    "ax = axs[1]\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, post_fitting_infer[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), post_fitting_infer['mean-2sigma'], post_fitting_infer['mean+2sigma'], alpha=0.2, color=\"red\", linewidth=0)\n",
    "\n",
    "axs[0].set_ylabel(r\"$f(x)$\")\n",
    "\n",
    "ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(r\"$x$\", labelpad=20)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caddaef-dee6-497b-8ef2-c14291ca9885",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Another example (this one is custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3a6ca-6299-421f-9326-14c23603d814",
   "metadata": {},
   "source": [
    "Another very simple example, but this one uses a custom function which is a bit trickier than the one above. That said, the procedure we take is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede54c8d-8bba-496d-ad5c-534caaaea6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "x1 = np.linspace(0, 0.5, 10)\n",
    "x3 = np.linspace(0.75, 1, 10)\n",
    "\n",
    "train_x = torch.FloatTensor(np.concatenate([x1, x3])).reshape(-1, 1)\n",
    "train_y = 5*train_x**2 + np.sin(train_x * 40) / 3 + torch.FloatTensor(np.random.normal(scale=0.1, size=train_x.shape))\n",
    "train_y = train_y\n",
    "\n",
    "grid = np.linspace(-2, 3, 1000).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c853c-81bd-4edc-aed1-6e1813e7c0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = gp.get_gp(train_x=train_x, train_y=train_y, gp_type=\"regression\")\n",
    "pre_fitting_infer = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d17c2-6d2b-400b-b343-e749f4ba569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = gp.train_gp_(model=model)\n",
    "post_fitting_infer = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a6443-988f-4208-a7b7-4ee90a80e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2), sharey=True, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, pre_fitting_infer[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pre_fitting_infer['mean-2sigma'], pre_fitting_infer['mean+2sigma'], alpha=0.2, color=\"red\", linewidth=0)\n",
    "\n",
    "ax = axs[1]\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, post_fitting_infer[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), post_fitting_infer['mean-2sigma'], post_fitting_infer['mean+2sigma'], alpha=0.2, color=\"red\", linewidth=0)\n",
    "\n",
    "axs[0].set_ylabel(r\"$f(x)$\")\n",
    "\n",
    "ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(r\"$x$\", labelpad=20)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219f586-edd6-41fa-8abc-2402e05c4a19",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bayesian optimization example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76018e-3d5c-470d-b603-a15c1fa67c1f",
   "metadata": {},
   "source": [
    "Follow along [here](https://botorch.org/tutorials/compare_mc_analytic_acquisition). This is a simple boilerplate example using a tutorial. We won't be visualizing/testing anything specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f8697-aadd-42c8-a47b-0225ee769a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions import Hartmann\n",
    "neg_hartmann6 = Hartmann(dim=6, negate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b547ae7-3eb9-41b8-92af-d49cdc0c6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.rand(10, 6)\n",
    "train_y = neg_hartmann6(train_x).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa813e6-211e-4e2d-bb1e-f4aae90b2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp.get_gp(train_x=train_x, train_y=train_y, gp_type=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d5c7c-61e9-41e1-afb8-8947c530e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gp.train_gp_(model=model, training_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b586cf7-ccb6-4328-92dd-bac87bd16d90",
   "metadata": {},
   "source": [
    "We'll use the `ExpectedImprovement` acquisition function for now. This requires `best_value`. To start, we'll use the standard analytic `EI`, which is implemented for us in `bo.ask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d958b-a8c9-4809-a17b-b2ba0b2feebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value = train_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea1494-c162-43a3-8ec1-cce45ce882d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # to keep the restart conditions the same\n",
    "with mode(debug=True):\n",
    "    asked_new_point = bo.ask(\n",
    "        model=model,\n",
    "        bounds=[(0, 1) for _ in range(6)],\n",
    "        acquisition_function=\"EI\",\n",
    "        acquisition_function_kwargs={\"best_f\": best_value},\n",
    "        optimize_acqf_kwargs={\"q\": 1, \"num_restarts\": 20, \"raw_samples\": 100}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a98c2-99f8-485c-a646-f0755f979a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_new_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bcddf-b04b-4267-b277-d2c6c636c76e",
   "metadata": {},
   "source": [
    "We can then use a Monte Carlo sampler implemented in `botorch`. These can seamlessly be passed to the `bo.ask` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af4e4a-a5c4-4280-bcdb-dc5c5fd2127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.sampling import SobolQMCNormalSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aab0a5-c9a9-4d44-bb41-ef40b2d060d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SobolQMCNormalSampler(num_samples=500, seed=0, resample=False)\n",
    "torch.manual_seed(seed=0) # to keep the restart conditions the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda4b73-e34c-4e4c-8dc3-b0c361ba17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_mc_point = bo.ask(\n",
    "    model=model,\n",
    "    bounds=[(0, 1) for _ in range(6)],\n",
    "    acquisition_function=qExpectedImprovement,\n",
    "    acquisition_function_kwargs={\"best_f\": best_value, \"sampler\": sampler},\n",
    "    optimize_acqf_kwargs={\"q\": 1, \"num_restarts\": 20, \"raw_samples\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff22a5e-66ba-43de-8430-af05abb8a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_mc_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338676e-fcd2-4674-b469-15607e72d2bd",
   "metadata": {},
   "source": [
    "Note that for the same random states the analytic and Monte Carlo results are in perfect agreement (and generally, they are always in _almost_ perfect agreement). Finally, we demonstrate the joint optimization of the acquisition function, the true power of `botorch`, where we can actually draw multiple samples at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5b684-6a0b-4417-8f74-cdf51c064399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SobolQMCNormalSampler(num_samples=500, seed=0, resample=False)\n",
    "torch.manual_seed(seed=0) # to keep the restart conditions the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c73e9-1456-4684-8127-392205433fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_mc_point = bo.ask(\n",
    "    model=model,\n",
    "    bounds=[(0, 1) for _ in range(6)],\n",
    "    acquisition_function=qExpectedImprovement,\n",
    "    acquisition_function_kwargs={\"best_f\": best_value, \"sampler\": sampler},\n",
    "    optimize_acqf_kwargs={\"q\": 2, \"num_restarts\": 20, \"raw_samples\": 512}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34789d50-823b-4149-a76b-0ddc89a2e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_mc_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71420af6-fe37-4cc0-8825-5b4e1d03c5c5",
   "metadata": {},
   "source": [
    "These sampled points are those which will _jointly_ optimize the acquisition function. In other words, we can \"ask\" for multiple points at a time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8040b7-51b5-402d-babb-a63ce5af95bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A practical active learning example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b0b75-b81b-48b3-9655-8a54771c53ca",
   "metadata": {},
   "source": [
    "Often we just want to \"plug-and-play\" with active learning to make e.g. experiments more efficient. It doesn't seem that `botorch` has simple active learning implementations, so we wrote our own. These are small modifications of the `UpperConfidenceBound` classes, where we basically set `beta -> infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523728b-6823-44b2-aef3-a1814494b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "x1 = np.linspace(0, 0.2, 20)\n",
    "x4 = np.linspace(1.4, 1.6, 20)\n",
    "train_x = torch.FloatTensor(np.concatenate([x1, x4])).reshape(-1, 1)\n",
    "train_y = 5*train_x**2 + np.sin(train_x * 50) / 3 + torch.FloatTensor(np.random.normal(scale=0.1, size=train_x.shape))\n",
    "train_y = train_y\n",
    "grid = np.linspace(-2, 3, 1000).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f89016-20d3-4de2-8234-1cb6c1f8af47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = gp.get_gp(train_x=train_x, train_y=train_y, gp_type=\"regression\")\n",
    "pred = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3261b-cd45-4223-b8e3-60f88c43b27a",
   "metadata": {},
   "source": [
    "For consistency with the other examples, here's the un-optimized GP conditioned on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424917d-8c9d-4b2d-9eef-59b49eadee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7479bbd8-588c-4839-bab4-27a337580bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = gp.train_gp_(model=model, training_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57231bc4-b8de-4f7d-8efb-82a3e1a404d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8b54f-4418-4430-91e6-7a2345111796",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab8411-d250-48ae-bec4-cba38d713591",
   "metadata": {},
   "source": [
    "## Ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485cbec-eca9-48a4-ae66-4c30ea880dfe",
   "metadata": {},
   "source": [
    "After optimization, we can play around with the `MaxVar` and `qMaxVar`policies. Lets start with the simpler analytic `MaxVar` policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72c231-60c9-4cfd-93b4-74f0effbf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb31aa5-6f6f-495a-9470-d49e6dae9ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds = [(-0.2, 1.9)]\n",
    "pt = bo.ask(\n",
    "    model=model,\n",
    "    bounds=bounds,\n",
    "    acquisition_function=\"MaxVar\",\n",
    "    acquisition_function_kwargs=dict(),\n",
    "    optimize_acqf_kwargs={\"q\": 1, \"num_restarts\": 20, \"raw_samples\": 512},\n",
    "    weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc29f96-7bb1-4bae-a84d-ce0826eee001",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pred = pred[\"observed_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a1c2e-4a20-4b90-9882-b0de66a41931",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(3, 2), gridspec_kw={'height_ratios': [1, 3]}, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(grid, observed_pred.variance.detach().numpy(), color=\"blue\")\n",
    "ax.axvline(pt.item(), linestyle=\"--\", color=\"black\")\n",
    "ax.axvline(bounds[0][0], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "ax.axvline(bounds[0][1], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.set_ylabel(r\"$\\sigma^2$\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "ax.axvline(pt.item(), linestyle=\"--\", color=\"black\")\n",
    "ax.axvline(bounds[0][0], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "ax.axvline(bounds[0][1], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.set_ylabel(r\"$f(x)$\")\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb015d6-057b-42b7-8c03-22eb26999f67",
   "metadata": {},
   "source": [
    "Now however, we can _jointly_ optimize the variance. Say that we can run 2 experiments in parallel. It might not be the case that the point chosen when just doing a sequential experiment is the same as one of the two points that are jointly optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2b102-f734-4d42-b75a-99ab40b18a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = bo.ask(\n",
    "    model=model,\n",
    "    bounds=[(-0.2, 1.5)],\n",
    "    acquisition_function=\"qMaxVar\",  # note the qMaxVar\n",
    "    acquisition_function_kwargs=dict(),\n",
    "    optimize_acqf_kwargs={\"q\": 2, \"num_restarts\": 20, \"raw_samples\": 512},  # Note q==2\n",
    "    # weight=lambda x: torch.abs(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44dc166-8a24-4fe8-b51e-f58d70ecabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab95382-72ad-44ce-a577-c5ea82c5a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(3, 2), gridspec_kw={'height_ratios': [1, 3]}, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(grid, observed_pred.variance.detach().numpy(), color=\"blue\")\n",
    "for pt in pts:\n",
    "    ax.axvline(pt.item(), linestyle=\"--\", color=\"black\")\n",
    "ax.axvline(bounds[0][0], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "ax.axvline(bounds[0][1], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.set_ylabel(r\"$\\sigma^2$\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(train_x.numpy(), train_y.numpy(), color=\"black\", s=0.5)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "for pt in pts:\n",
    "    ax.axvline(pt.item(), linestyle=\"--\", color=\"black\")\n",
    "ax.axvline(bounds[0][0], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "ax.axvline(bounds[0][1], linestyle=\"--\", linewidth=0.5, color=\"black\")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.set_ylabel(r\"$f(x)$\")\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb2f7-65d0-4fbd-9d54-589164785f7f",
   "metadata": {},
   "source": [
    "Indeed, these are not the same points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b5cd65-24ff-4fb6-bcad-9d770dd35f6d",
   "metadata": {},
   "source": [
    "## Tell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc581575-592b-43ab-b33a-b0ab8f7826c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = torch.tensor(np.array([-1.5, -1.0]).reshape(-1, 1)).float()\n",
    "new_y = torch.tensor(np.array([5.0, 4.0])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9462b72-c361-4306-9970-48d8196cc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = gp.tell(model=model, new_x=new_x, new_y=new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cab20f-6b8d-4d06-875c-74612b9aaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x, new_y = gp.get_training_data(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a750b-e0d3-483e-9372-0dafa4361f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gp.infer(model=new_model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e924b8e-6655-46b2-9d98-832b9619ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.scatter(new_model.train_inputs[0].detach().numpy(), new_model.train_targets.detach().numpy(), color=\"black\", s=3)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c46a9-e804-47cf-aebb-c87978442000",
   "metadata": {},
   "source": [
    "Using the new model (and note, we've told it about the new data), we can then refine the hyperparameters further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3975ded-d7aa-4de4-82d9-94f1699cbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpytorch.settings.debug(False):\n",
    "    losses = gp.train_gp_(model=new_model, training_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91eceb4-6290-4fd8-83e4-03498b5cef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gp.infer(model=new_model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f0aee-2bba-428b-9a7e-2fba327d6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.scatter(new_model.train_inputs[0].detach().numpy(), new_model.train_targets.detach().numpy(), color=\"black\", s=3)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5cf4a9-e90c-4316-b630-c559b3e8c653",
   "metadata": {},
   "source": [
    "We often want to then improve the model with the next-sampled point. We can do this in two flavors.\n",
    "- Recondition the GP, but don't revise the hyperparameters\n",
    "- Recondition the GP, but do re-train the hyperparamters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4e138-0d39-4144-8506-6ed8d984bde3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A toy experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5da94-c893-496e-b4ca-231041ebfb79",
   "metadata": {},
   "source": [
    "Let's now consider the holy grail: we want to run an experiment according to some policy (e.g. to find the best interpolating function which is very certain everywhere, or to maximize some quantity). Let's do this on a toy source of truth that is easy to visualize. We'll use the same function as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06d819-7705-40bd-a7e0-7a6951ad9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth(x):\n",
    "    if isinstance(x, (float, int)):\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "    return 5*x**2 + torch.sin(x * 50) / 3 + torch.FloatTensor(np.random.normal(scale=0.2, size=x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46597ea8-bf47-48a0-8d1e-1b3359cbceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "x1 = np.linspace(0, 0.2, 2)\n",
    "x4 = np.linspace(1.4, 1.6, 2)\n",
    "train_x = torch.FloatTensor(np.concatenate([x1, x4])).reshape(-1, 1)\n",
    "train_y = truth(train_x)\n",
    "grid = np.linspace(-2, 3, 1000).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a5dff-b172-4713-bfec-3690bb648003",
   "metadata": {},
   "source": [
    "We begin by initializing a model on minimal training data, as usual, and then training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66b995-a958-4e24-bdda-a33e925e5ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = gp.get_gp(train_x=train_x, train_y=train_y, gp_type=\"regression\")\n",
    "_ = gp.train_gp_(model=model, training_iter=1000)\n",
    "pred = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7035eaf-5306-4510-88fe-3cf504e251c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.scatter(train_x.detach().numpy(), train_y.detach().numpy(), color=\"black\", s=3)\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74bba2c-ee47-4b03-b459-270327124990",
   "metadata": {},
   "source": [
    "Consider that we wish to do simple active learning. In that case, we want to create a loop, where the at each instance of the loop we \"ask\" for a new point, query the source of `truth`, and add that data back to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24dc9e-72c8-497b-b045-8dd1807b2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silly_weight(x):\n",
    "    where = (x > 0) & (x < 1)\n",
    "    weights = torch.zeros(x.shape)\n",
    "    weights[where] = 1\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a328db8-b303-47ad-9681-42e1f13514ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "NLOOP = 10\n",
    "\n",
    "for ii in range(NLOOP):\n",
    "    candidate = bo.ask(\n",
    "        model=model,\n",
    "        bounds=[(-2, 3)],\n",
    "        acquisition_function=\"qMaxVar\",\n",
    "        optimize_acqf_kwargs={\n",
    "            \"q\": 1,\n",
    "            \"num_restarts\": 5,\n",
    "            \"raw_samples\": 20,\n",
    "        },\n",
    "        weight=None\n",
    "    )\n",
    "    model = gp.tell(model=model, new_x=candidate, new_y=truth(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507f099-2f36-4aa5-afcc-309c1e778682",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gp.train_gp_(model=model, training_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1ba03-2ae7-4d5f-a744-f8e3f7c802c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a60c03-c178-4580-b65e-12df3a6f597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x, new_y = gp.get_training_data(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff14412-8596-449e-8e14-43e5ea39cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "\n",
    "ax.plot(grid, pred[\"mean\"], \"r-\")\n",
    "ax.fill_between(grid.squeeze(), pred['mean-2sigma'], pred['mean+2sigma'], alpha=0.5)\n",
    "ax.scatter(new_x, new_y, color=\"black\", s=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5a2a1-b5d1-4ff6-91ec-a6ba90320916",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2d input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c5291-2aac-44eb-a741-56824477ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grids_to_coordinates(grids):\n",
    "    x = np.meshgrid(*grids)\n",
    "    return np.array([xx.flatten() for xx in x]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1052ecc-d8ac-4dcb-ab40-c1a80ad5f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(127)\n",
    "N = 100\n",
    "M = 150\n",
    "idx = np.random.choice([xx for xx in range(N*M)], 20, replace=False)\n",
    "idx.sort()\n",
    "\n",
    "grid_x = np.linspace(-4, 5, N)\n",
    "grid_y = np.linspace(-5, 4, M)\n",
    "\n",
    "# Feature data\n",
    "g1, g2 = np.meshgrid(grid_x, grid_y)\n",
    "X = np.array([g1.flatten(), g2.flatten()]).T\n",
    "X = X[idx, :]\n",
    "\n",
    "X_original = X.copy()\n",
    "\n",
    "# alpha = (np.linspace(-2, 2, N**2)[idx])**2 * 0  # Noise/uncertainty\n",
    "alpha = np.array([1e-5 for _ in range(len(X))])\n",
    "\n",
    "def func(x, y):\n",
    "    return (1 - x / 3. + x ** 5 + y ** 5) * np.exp(-x ** 2 - y ** 2) + np.exp(-(x - 2)**2 - (y + 4)**2)\n",
    "\n",
    "def truth(X):\n",
    "    x = X[:, 0]\n",
    "    y = X[:, 1]\n",
    "    return func(x, y)\n",
    "\n",
    "def truth_meshgrid(x, y):\n",
    "    x = x.reshape(-1, 1)\n",
    "    y = y.reshape(1, -1)\n",
    "    return func(x, y)\n",
    "    \n",
    "\n",
    "y = truth(X)  # Target data\n",
    "y = y.reshape(-1, 1)\n",
    "train_x = X\n",
    "train_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47601901-c7c4-49ee-9c3b-5fc6d374817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grids_to_coordinates([grid_x, grid_y])\n",
    "z = truth_meshgrid(grid_x, grid_y)\n",
    "z_min = -np.abs(z).max()\n",
    "z_max = np.abs(z).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b668d29-f653-4393-a2f4-28236df05a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp.get_gp(train_x=train_x, train_y=train_y, gp_type=\"regression\")\n",
    "_ = gp.train_gp_(model=model, training_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b23e18-5abf-42c0-9b8a-a2c7b5481328",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3619bbb-cf0e-45d4-b261-3f7500e4272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pred[\"mean\"].reshape(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37a8e3-440d-46ff-bd53-15ec9c0b9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3), sharey=True, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "c = ax.imshow(\n",
    "    z.T, cmap='rainbow', vmin=z_min, vmax=z_max,\n",
    "    extent=[grid_x.min(), grid_x.max(), grid_y.min(), grid_y.max()],\n",
    "    interpolation ='nearest', origin ='lower'\n",
    ")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.set_title(\"Function\")\n",
    "\n",
    "ax = axs[1]\n",
    "c = ax.imshow(\n",
    "    mu, cmap='rainbow', vmin=z_min, vmax=z_max,\n",
    "    extent=[grid_x.min(), grid_x.max(), grid_y.min(), grid_y.max()],\n",
    "    interpolation ='nearest', origin ='lower'\n",
    ")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.scatter(train_x[:, 0], train_x[:, 1], s=0.3, color=\"black\")\n",
    "# ax.scatter(X_original[:, 0], X_original[:, 1], s=0.3, color=\"blue\")\n",
    "ax.set_title(\"GP\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00b9e2-ed74-4884-b485-0baf58bb4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(x):\n",
    "    # x should be of shape [..., 2]\n",
    "    # lets weight the y-value a lot if its order of magnitude is high\n",
    "    return torch.abs(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08763431-9b18-4bba-834b-f7ca09196463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "NLOOP = 20\n",
    "\n",
    "for ii in range(NLOOP):\n",
    "    candidate = bo.ask(\n",
    "        model=model,\n",
    "        bounds=[(-4, 5), (-5, 4)],\n",
    "        acquisition_function=\"qUpperConfidenceBound\", # acquisition_function=\"MaxVar\",\n",
    "        acquisition_function_kwargs={\"beta\": 0.1},\n",
    "        optimize_acqf_kwargs={\n",
    "            \"q\": 1,\n",
    "            \"num_restarts\": 5,\n",
    "            \"raw_samples\": 20,\n",
    "        },\n",
    "        weight=weight\n",
    "    )\n",
    "    model = gp.tell(model=model, new_x=candidate, new_y=truth(candidate).reshape(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4605e37-1912-4c49-96f6-ead807484bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gp.train_gp_(model=model, training_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00ee6f-151a-4497-b37f-ba2fbb05ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gp.infer(model=model, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad87c11-a291-4399-b605-e03ec499228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pred[\"mean\"].reshape(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe1917-af83-497a-a905-a0d22e82ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x, new_y = gp.get_training_data(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0fdbe-771d-4b53-9159-f3890c379b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3), sharey=True, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "c = ax.imshow(\n",
    "    z.T, cmap='rainbow', vmin=z_min, vmax=z_max,\n",
    "    extent=[grid_x.min(), grid_x.max(), grid_y.min(), grid_y.max()],\n",
    "    interpolation ='nearest', origin ='lower'\n",
    ")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.set_title(\"Function\")\n",
    "\n",
    "ax = axs[1]\n",
    "c = ax.imshow(\n",
    "    mu, cmap='rainbow', vmin=z_min, vmax=z_max,\n",
    "    extent=[grid_x.min(), grid_x.max(), grid_y.min(), grid_y.max()],\n",
    "    interpolation ='nearest', origin ='lower'\n",
    ")\n",
    "adj.set_grids(ax, grid=False)\n",
    "ax.scatter(new_x[:, 0], new_x[:, 1], s=0.3, color=\"black\")\n",
    "# ax.scatter(X_original[:, 0], X_original[:, 1], s=0.3, color=\"blue\")\n",
    "ax.set_title(\"GP\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0182cba-a46d-447f-ba50-0271cbc6468d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
